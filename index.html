<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="alternate"
      type="appliation/rss+xml"
      href="http://bastibe.de/rss.xml"
      title="RSS feed for http://bastibe.de/">
<title>Bastibe.de</title><meta  name="author" content="Bastian Bechtold" />
<link href='http://fonts.googleapis.com/css?family=Roboto&subset=latin' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet' type='text/css'>
<link href= "static/style.css" rel="stylesheet" type="text/css" />
<link rel="icon" href="static/favicon.ico">
<link rel="apple-touch-icon-precomposed" href="static/favicon-152.png">
<link rel="msapplication-TitleImage" href="static/favicon-144.png">
<link rel="msapplication-TitleColor" href="#0141ff">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"> </script>
<meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8" />
<meta name="viewport" content="initial-scale=1,width=device-width,minimum-scale=1"></head>
<body>
<div id="preamble" class="status"><div class="header">
  <a href="http://bastibe.de">Basti's Scratchpad on the Internet</a>
  <div class="sitelinks">
    <a href="http://alpha.app.net/bastibe">alpha.app.net</a> | <a href="http://github.com/bastibe">Github</a>
  </div>
</div></div>
<div id="content"><div class="post-date">29 Sep 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-09-29-numpy-broadcasting-rules.html">Numpy Broadcasting Rules</a></h1>
<p>
They say that all arithmetic operations in Numpy behave like their element-wise cousins in Matlab. This is wrong, and seriously tripped me up last week.
</p>

<p>
In particular, this is what happens when you multiply an array with a matrix<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup> in Numpy:
</p>

<pre class="example">
     [[  1],           [[1, 2, 3],       [[ 1,    2,   3],
      [ 10],       *    [4, 5, 6],   =    [ 40,  50,  60],
      [100]]            [7, 8, 9]]        [700, 800, 900]]

 [  1,  10, 100]       [[1, 2, 3],       [[  1,  20, 300],
        OR         *    [4, 5, 6],   =    [  4,  50, 600],
[[  1,  10, 100]]       [7, 8, 9]]        [  7,  80, 900]]
</pre>

<p>
They behave as if each row was evaluated separately, and singular dimensions are repeated where necessary. It helps to think about them as row-wise, instead of element-wise. This is particularly important in the second example, where the <i>whole</i> 1d-array is multiplied with <i>every row</i> of the 2d-array.
</p>

<p>
Note that this is <i>not</i> equivalent to multiplying every <i>element</i> as in <code>[a[n]*b[n] for n in range(len(a))]</code>. I guess that's why this is called <i>broadcasting</i>, and not <i>element-wise</i>.
</p>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
"matrix" here refers to a 2-d <code>numpy.array</code>. There is also a <code>numpy.matrix</code>, where multiplication is matrix multiplication, but this is not what I'm talking about.
</p></div></div>


</div>
</div><div class="post-date">28 Sep 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-09-28-python-performance.html">Python Numeric Performance</a></h1>
<p>
Recently, I was working on a dynamic programming algorithm that involves a lot of number crunching in nested loops. The algorithm looks like this:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_change_probability_python</span>(oct_per_sec):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">b</span> = 1.781
    <span style="color: #2e8b57;">mu</span> = -0.301
    <span style="color: #1c86ee;">return</span> 1/(2*b)*math.exp(-<span style="color: #cd6600;">abs</span>(oct_per_sec-mu)/b)

<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_idx_range_python</span>(y_idx, max_y_factor, height):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">y</span> = (y_idx/height)*(max_y-min_y)+min_y
    <span style="color: #2e8b57;">y_lo</span> = <span style="color: #cd6600;">max</span>(y/max_y_factor, min_y)
    <span style="color: #2e8b57;">y_hi</span> = <span style="color: #cd6600;">min</span>(y*max_y_factor, max_y)
    <span style="color: #2e8b57;">y_lo_idx</span> = <span style="color: #cd6600;">int</span>((y_lo-min_y)/(max_y-min_y)*height)
    <span style="color: #2e8b57;">y_hi_idx</span> = <span style="color: #cd6600;">int</span>((y_hi-min_y)/(max_y-min_y)*height)
    <span style="color: #1c86ee;">return</span> y_lo_idx, y_hi_idx

<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">find_tracks_python</span>(cost_matrix, delta_x):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">tracks</span> = np.zeros(correlogram.shape, dtype=np.int64)
    <span style="color: #2e8b57;">cum_cost</span> = np.zeros(correlogram.shape)

    <span style="color: #2e8b57;">max_y_factor</span> = (2**5)**(delta_x)
    <span style="color: #2e8b57;">height</span> = correlogram.shape[1]

    <span style="color: #2e8b57;">probabilities</span> = np.empty((height, height))
    <span style="color: #1c86ee;">for</span> y_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(height):
        <span style="color: #2e8b57;">y</span> = (y_idx/height)*(max_y-min_y)+min_y
        <span style="color: #1c86ee;">for</span> y_pre_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(*y_idx_range_numba(y_idx, max_y_factor, height)):
            <span style="color: #2e8b57;">y_pre</span> = (y_pre_idx/height)*(max_y-min_y)+min_y
            <span style="color: #2e8b57;">doubles_per_x</span> = math.log2((y/y_pre)**(1/delta_x))
            <span style="color: #2e8b57;">probabilities</span>[y_idx, y_pre_idx] = y_change_probability_numba(doubles_per_x)

    <span style="color: #1c86ee;">for</span> x_idx, cost_column <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">enumerate</span>(cost_matrix):
        <span style="color: #1c86ee;">if</span> x_idx == 0:
            <span style="color: #2e8b57;">cum_cost</span>[x_idx] = cost_column
            <span style="color: #1c86ee;">continue</span>
        <span style="color: #1c86ee;">for</span> y_idx, cost <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">enumerate</span>(cost_column):
            <span style="color: #1c86ee;">for</span> y_pre_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(*y_idx_range_numba(y_idx, max_y_factor, height)):
                <span style="color: #2e8b57;">weighted_cum_cost</span> = cum_cost[x_idx-1, y_pre_idx] + cost*probabilities[y_idx, y_pre_idx]
                <span style="color: #1c86ee;">if</span> weighted_cum_cost &gt; cum_cost[x_idx, y_idx]:
                    <span style="color: #2e8b57;">cum_cost</span>[x_idx, y_idx] = weighted_cum_cost
                    <span style="color: #2e8b57;">tracks</span>[x_idx, y_idx] = y_pre_idx
            <span style="color: #2e8b57;">cum_cost</span>[x_idx, y_idx] = cum_cost[x_idx-1, tracks[x_idx, y_idx]] + cost

    <span style="color: #1c86ee;">return</span> tracks, cum_cost
</pre>
</div>

<p>
I'm not going into the details of what this algorithm does, but note that it iterates over every column and row of the matrix <code>cost_matrix</code>, and then iterates over another range <code>previous_y_range</code> for each of the values in <code>cost_matrix</code>. On the way, it does a lot of basic arithmetic and some algebra.
</p>

<p>
The problem is, this is very slow. For a \(90 \times 200\) <code>cost_matrix</code>, this takes about 260Â ms. Lots of loops? Lots of simple mathematics? Slow? That sounds like a perfect match for <a href="http://www.numpy.org/">Numpy</a>!
</p>

<p>
If you can express your code in terms of linear algebra, Numpy will execute them in highly-optimized C code. The problem is, translating loops into linear algebra is not always easy. In this case, it took some effort:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_change_probability_numpy</span>(doubles_per_x):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">b</span> = 1.781
    <span style="color: #2e8b57;">mu</span> = -0.301
    <span style="color: #1c86ee;">return</span> 1/(2*b)*np.exp(-np.<span style="color: #cd6600;">abs</span>(doubles_per_x-mu)/b)

<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">find_frequency_tracks_numpy</span>(cost_matrix, delta_x):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">tracks</span> = np.zeros(cost_matrix.shape, dtype=np.<span style="color: #cd6600;">int</span>)
    <span style="color: #2e8b57;">cum_cost</span> = np.zeros(cost_matrix.shape)

    <span style="color: #2e8b57;">max_y_factor</span> = (2**5)**(delta_t) <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">allow at most 5 octaves per second (3 sigma)</span>
    <span style="color: #2e8b57;">height</span> = cost_matrix.shape[1]

    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">pre-allocate probabilities matrix as minus infinity. This matrix</span>
    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">will be sparsely filled with positive probability values, and</span>
    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">empty values will have minus infinite probability.</span>
    <span style="color: #2e8b57;">probabilities</span> = -np.ones((height, height))*np.inf
    <span style="color: #1c86ee;">for</span> y_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(probabilities.shape[0]):
        <span style="color: #2e8b57;">y</span> = (y_idx/height)*(max_y-min_y)+min_y
        <span style="color: #2e8b57;">y_pre_idx</span> = np.arange(<span style="color: #cd6600;">int</span>((<span style="color: #cd6600;">max</span>(y/max_y_factor, min_y)-min_y)/(max_y-min_y)*height),
                              <span style="color: #cd6600;">int</span>((<span style="color: #cd6600;">min</span>(y*max_y_factor, max_y)-min_y)/(max_y-min_y)*height))
        <span style="color: #2e8b57;">y_pre</span> = (y_pre_idx/height)*(max_y-min_y)+min_y
        <span style="color: #2e8b57;">doubles_per_x</span> = np.log2((y/y_pre)**(1/delta_x))
        <span style="color: #2e8b57;">probabilities</span>[y_idx, y_pre_idx] = y_change_probability(doubles_per_x)

    <span style="color: #2e8b57;">cum_cost</span>[0] = cost_matrix[0]
    <span style="color: #1c86ee;">for</span> x_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(1, <span style="color: #cd6600;">len</span>(cost_matrix)):
        <span style="color: #2e8b57;">cost_column</span> = cost_matrix[x_idx:x_idx+1] <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">extract cost_column as 2d-vector!</span>
        <span style="color: #2e8b57;">weighted_cum_cost</span> = cum_cost[x_idx-1] + cost_column.T*probabilities
        <span style="color: #2e8b57;">tracks</span>[x_idx] = np.argmax(weighted_cum_cost, axis=1)
        <span style="color: #2e8b57;">cum_cost</span>[x_idx] = cum_cost[x_idx-1, tracks[x_idx]] + cost_column

    <span style="color: #1c86ee;">return</span> tracks, cum_corrs
</pre>
</div>

<p>
This code does not look much like the original, but calculates exactly the same thing. This takes about 15Â ms for a \(90 \times 200\) <code>cost_matrix</code>, which is about 17 times faster than the original code! Yay Numpy! And furthermore, this code is arguably more readable than the original, since it is written at a higher level of abstraction.
</p>

<p>
Another avenue for performance optimization is <a href="http://numba.pydata.org/">Numba</a>. Numba applies dark and powerful magic to compile humble Python functions into blazingly fast machine code. It is proper magic, if you ask me. Simply add an innocuous little decorator to your functions, and let Numba do it's thing. If all goes well, your code will work just as before, except with unheard-of performance:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #00688b;">@jit</span>(numba.float64(numba.float64), nopython=<span style="color: #6e8b3d;">True</span>)
<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_change_probability_numba</span>(doubles_per_x):
    ...

<span style="color: #00688b;">@jit</span>((numba.int64, numba.float64, numba.int64), nopython=<span style="color: #6e8b3d;">True</span>)
<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_idx_range_numba</span>(y_idx, max_y_factor, height):
    ...

<span style="color: #00688b;">@jit</span>((numba.float64[:,:], numba.float64), nopython=<span style="color: #6e8b3d;">True</span>)
<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">find_tracks_numba</span>(cost_matrix, delta_t):
    ...
</pre>
</div>

<p>
However, Numba is no silver bullet, and does not support all of Python yet. In the present case, it is missing support for <code>enumerate</code> for Numpy matrices. Thus, I had to rewrite the first two loops like this:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">python version</span>
<span style="color: #1c86ee;">for</span> x_idx, cost_column <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">enumerate</span>(cost_matrix):
    ...

<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">numba version</span>
<span style="color: #1c86ee;">for</span> x_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(<span style="color: #cd6600;">len</span>(cost_matrix)):
    <span style="color: #2e8b57;">cost_column</span> = cost_matrix[x_idx]
    ...
</pre>
</div>

<p>
Another area that proved problematic is N-D slice writing. Instead of using expressions like <code>m1[x,y:y+3] = m2</code>, you have to write <code>for idx in range(3): m1[x,y+idx] = m2[idx]</code>. Not a difficult transformation, but it basically forced me to unroll all the nice vectorized code of the Numpy version back to their original pure-Python form. That said, Numba is getting better and better, and many constructs that used to be uncompilable (<code>yield</code>) are not a problem any more.
</p>

<p>
Anyway, with that done, the above code went down from 260Â ms to 2.2Â ms. This is a 120-fold increase in performance, and still seven times faster than Numpy, with minimal code changes. This is proper magic!
</p>

<p>
So why wouldn't you just always use Numba? After all, when it comes down to raw performance, Numba is the clear winner. The big difference between performance optimization using Numpy and Numba is that properly vectorizing your code for Numpy often reveals simplifications and abstractions that make it easier to reason about your code. Numpy forces you to think in terms of vectors, matrices, and linear algebra, and this often makes your code <i>more beautiful</i>. Numba on the other hand often requires you to make your code <i>less beautiful</i> to conform to it's subset of compilable Python.
</p>
<div class="post-date">22 Apr 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-04-22-matlab-and-audio-files.html">Matlab and Audio Files</a></h1>
<p>
So I wanted to work with audio files in Matlab. In the past, Matlab could only do this with <code>auread</code> and <code>wavread</code>, which can read <i>*.au</i> and <i>*.wav</i> files. With 2012b, Matlab introduced <a href="http://mathworks.com/help/matlab/ref/audioread.html"><code>audioread</code></a>, which claims to support <i>*.wav</i>, <i>*.ogg</i>, <i>*.flac</i>, <i>*.au</i>, <i>*.mp3</i>, and <i>*.mp4</i>, and simultaneously deprecated <code>auread</code> and <code>wavread</code>.
</p>

<p>
Of these file formats, only <i>*.au</i> is capable of storing more than 4 Gb of audio data. But the documentation is actually wrong: <code>audioread</code> can <i>actually</i> read more data formats than documented: it reads <i>*.w64</i>, <i>*.rf64</i>, and <i>*.caf</i> no problem. And these can store more than 4 Gb as well.
</p>

<p>
It's just that, while <code>audioread</code> supports all of these nice file formats, <a href="http://mathworks.com/help/matlab/ref/audiowrite.html"><code>audiowrite</code></a> is more limited, and only supports <i>*.wav</i>, <i>*.ogg</i>, <i>*.flac</i>, and <i>*.mp4</i>. And it does not support any undocumented formats, either. So it seems that there is no way of writing files larger than 4 Gb. But for the time being, <code>auwrite</code> is still available, even though deprecated. I tried it, though, and it didn't finish writing 4.8 Gb in half an hour.
</p>

<p>
In other words, Matlab is incapable of writing audio files larger than 4 Gb. It just can't do it.
</p>
<div class="post-date">15 Apr 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-04-15-unicode-in-the-matlab-command-line.html">Unicode and Matlab on the command line</a></h1>
<p>
As per the latest <a href="http://stackoverflow.com/research/developer-survey-2015#techSuper-dreaded">Stackoverflow Developer Survey</a>, Matlab is one of <i>the</i> most dreaded tools out there. I run into Matlab-related trouble daily. In all honesty, I have never seen a programming language as user-hostile and as badly designed as this.
</p>

<p>
So here is today's problem: When run from the command line, Matlab does not render unicode characters (on OSX).
</p>

<p>
I say "(on OSX)", because on Windows, it does not print a damn thing. Nope, no <code>disp</code> output for Windows users.
</p>

<p>
More analysis: It's not that Matlab does not render unicode characters at all when run from the command line. Instead, it renders them as <code>0x1a</code> aka <code>SUB</code> aka <i>substitute character</i>. In other words, it tries to render unicode as ASCII (which doesn't work), and then replaces all non-ASCII characters with <code>SUB</code>. This is actually reasonable if Matlab were running on a machine that can't handle unicode. This is not a correct assessment of post-90s Macs, though.
</p>

<p>
To see why Matlab would do such a dastardly deed, you can use <code>feature('locale')</code> to get information about the encoding Matlab uses. On Windows and OS X, this defaults to either <code>ISO-8859-1</code> (when your locale is pure <code>de_DE</code> or <code>en_US</code>) or <code>US-ASCII</code>, if it is something impure. In my case, German dates but English text. Because <code>US-ASCII</code> is obviously the most all-encompassing choice for such mixed-languages environments.
</p>

<p>
But luckily, there is help. Matlab has a widely documented (not) and easily discoverable (not) configuration option to change this: To change Matlab's encoding settings, edit <code>%MATLABROOT%/bin/lcdata.xml</code>, and look for the entry for your locale. For me, this is one of
</p>

<div class="org-src-container">

<pre class="src src-xml">&lt;<span style="color: #cd9b1d;">locale</span> <span style="color: #2e8b57;">name</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">de_DE</span><span style="color: #8b7355;">"</span> <span style="color: #2e8b57;">encoding</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">ISO-8859-1</span><span style="color: #8b7355;">"</span> <span style="color: #2e8b57;">xpg_name</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">de_DE.ISO8859-1</span><span style="color: #8b7355;">"</span>&gt; ...
&lt;<span style="color: #cd9b1d;">locale</span> <span style="color: #2e8b57;">name</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">en_US</span><span style="color: #8b7355;">"</span> <span style="color: #2e8b57;">encoding</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">ISO-8859-1</span><span style="color: #8b7355;">"</span> <span style="color: #2e8b57;">xpg_name</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">en_US.ISO8859-1</span><span style="color: #8b7355;">"</span>&gt; ...
</pre>
</div>

<p>
In order to make Matlab's encoding default to UTF-8, change the entry for your locale to
</p>

<div class="org-src-container">

<pre class="src src-xml">&lt;<span style="color: #cd9b1d;">locale</span> <span style="color: #2e8b57;">name</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">de_DE</span><span style="color: #8b7355;">"</span> <span style="color: #2e8b57;">encoding</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">UTF-8</span><span style="color: #8b7355;">"</span> <span style="color: #2e8b57;">xpg_name</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">de_DE.UTF-8</span><span style="color: #8b7355;">"</span>&gt; ...
&lt;<span style="color: #cd9b1d;">locale</span> <span style="color: #2e8b57;">name</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">en_US</span><span style="color: #8b7355;">"</span> <span style="color: #2e8b57;">encoding</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">UTF-8</span><span style="color: #8b7355;">"</span> <span style="color: #2e8b57;">xpg_name</span>=<span style="color: #8b7355;">"</span><span style="color: #8b7355;">en_US.UTF-8</span><span style="color: #8b7355;">"</span>&gt; ...
</pre>
</div>

<p>
With that, Matlab will print UTF-8 to the terminal.
</p>

<p>
You still can't type unicode characters to the command prompt, of course. But who would want that anyway, I dare ask. Of course, what with Matlab being basically free, and frequently updated, we can forgive such foibles easily&#x2026;
</p>
<div class="post-date">12 Apr 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-04-12-decisions-in-poe.html">Decisions in Pillars of Eternity</a></h1>
<p>
Early on in <a href="https://en.wikipedia.org/wiki/Pillars_of_Eternity">Pillars of Eternity</a>, you are tasked to kill one of two characters: Either you kill King Rethoric, who executed many innocent people, or you kill Rolsc, the leader of the rebellion. This is an interesting moral choice, but it is also profoundly sad that the game presents killing either of them as the only resolution to this conflict.
</p>

<p>
It got me thinking. In the real world, I would not consider killing to be an option, ever. But in the game, you have to play by the game's rules. And furthermore, you can't just walk away and have the two characters duke it out amongst themselves: The whole game is built around the player, and without the player's interaction, the game world doesn't evolve.
</p>

<p>
Thus, this conflict won't resolve itself, and the player is forced to kill. I wish there were a diplomatic option, or a way of fixing the underlying problem so the two characters are not at odds any more. I fear how these choices in video games might influence our perceptions of everyday choices, and crave for video games that offer interesting choices that do not revolve around murder.
</p>

<p>
From what I hear, Planescape Torment did offer such choices. As did many of <a href="https://en.wikipedia.org/wiki/Gone_Home">my</a> <a href="https://en.wikipedia.org/wiki/The_Stanley_Parable">favorite</a> <a href="https://en.wikipedia.org/wiki/X-Plane_%28simulator%29">games</a> <a href="https://en.wikipedia.org/wiki/Civilization_V">of</a> <a href="https://en.wikipedia.org/wiki/The_Wolf_Among_Us">all</a> <a href="https://en.wikipedia.org/wiki/The_Witcher_%28video_game%29">times</a>.
</p>
<div id="archive">
  <a href="archive.html">Older posts</a>
</div>
</div>
</body>
