<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<link rel="alternate"
      type="application/rss+xml"
      href="https://bastibe.de/rss.xml"
      title="RSS feed for https://bastibe.de/"/>
<title>Bastibe.de</title>
<meta name="author" content="Bastian Bechtold">
<meta name="referrer" content="no-referrer">
<link href= "static/style.css" rel="stylesheet" type="text/css" />
<link rel="icon" href="static/favicon.ico">
<link rel="apple-touch-icon-precomposed" href="static/favicon-152.png">
<link rel="msapplication-TitleImage" href="static/favicon-144.png">
<link rel="msapplication-TitleColor" href="#0141ff">
<script src="static/katex.min.js"></script>
<script src="static/auto-render.min.js"></script>
<link rel="stylesheet" href="static/katex.min.css">
<script>document.addEventListener("DOMContentLoaded", function() { renderMathInElement(document.body); });</script>
<meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8">
<meta name="viewport" content="initial-scale=1,width=device-width,minimum-scale=1"></head>
<body>
<div id="preamble" class="status"><div class="header">
  <a href="https://bastibe.de">Basti's Scratchpad on the Internet</a>
  <div class="sitelinks">
    <a href="https://twitter.com/paperflyer">Twitter</a> | <a href="https://github.com/bastibe">Github</a> | <a href="https://bastibe.de/projects.html">Projects</a>
  </div>
</div></div>
<div id="content">

<div class="post-date">11 Sep 2019</div><h1 class="post-title"><a href="2019-09-11-how-we-perceive-speech.html">How we perceive Speech</a></h1>
<p>
Now that I am officially a <a href="https://bastibe.de/2019-07-09-publish-or-perish.html">failed scientist</a>, I might as well talk about my research in public. I spent the last few years analyzing speech recordings. Particularly, <i>voiced speech</i>, where vibrations in the vocal folds excite resonances in the vocal tract, and a tonal sound leaves our mouths and noses.
</p>

<p>
As humans, we are particularly tuned to recognizing these kinds of sounds. Even in loud background noise, even with dozens of people talking at the same time, we can clearly identify the sound of a human voice (even if we might not be able to understand the words).
</p>


<figure>
<img src="https://bastibe.de/static/2019-09/spectrogram.png" alt="spectrogram.png">

<figcaption><span class="figure-number">Figure 1: </span>A spectrogram of speech (it's me, saying: "Es war einmal ein Mann")</figcaption>
</figure>

<p>
Looking at these sounds from a physical point of view, we can see that it is made up of a fundamental frequency at the voice's pitch, and harmonics at integer multiples of the fundamental. And even though the sound is clearly composed of multiple harmonics, we perceive it as a single sound with a single pitch. Even more perplexing, we attribute all of these harmonics to a single voice, even if they criss-cross with tonal sounds from different sources.
</p>

<p>
Yet, speech recognition systems regularly struggle with such tasks, unless we feed them unholy amounts of data and processing power. In other words, there has to be more to speech than the simple figure above indicates.
</p>

<p>
One area is definitely time resolution. Obviously, when the vocal folds open to admit a puff of air into the vocal tract, phases align, and loudness is higher than when the vocal folds have closed again and phases go out of sync. This happens several hundreds of times per second, at the frequency of the fundamental. Yet, this phase coherence is invisible in most of our visualizations, such as the spectrogram above, or the MFCCs usually used in speech recognition, as they are too coarse for such short-time detail.
</p>

<p>
An even more interesting detail emerges from fMRI scans of people who are speaking, and people who are listening to speech: their activation patterns are strikingly similar. As in, motor groups are activating when listening, just as if actual speech muscles were moved. To me, this indicates that when we listen to speech, we <i>simulate speaking</i>. And I find it highly likely that we understand speech mostly in terms of the movements we would have to make to imitate it. In other words, we do not internalize speech as an <i>audio</i> signal, but as <i>muscle movements</i>.
</p>

<p>
This matches another observation from a different area: When learning a foreign language, we can not hear what we can not produce. If you didn't learn how to speak an Ö and Ü (two German umlauts) as a child, you will have a hard time hearing the difference as an adult. Yet they sound completely distinct to me. In a production model, this makes a lot of sense, as we wouldn't know how to simulate a sound we can not produce.
</p>

<p>
Bringing this back to the science of signal processing, I believe that most speech analysis algorithms are currently lacking a production model of speech. Speech can not be fully understood as an audio signal. It needs to be understood in terms of the variables and limitations of a human vocal tract. I believe that if we integrated such a physiological production model into our machine learning models, we wouldn't need to feed them such vast amounts of data and electricity, and might even get by without them.
</p>
<div class="taglist"><a href="tags.html">Tags:</a> <a href="tag-signal-processing.html">signal-processing</a> </div>
<div class="post-date">09 Jul 2019</div><h1 class="post-title"><a href="2019-07-09-publish-or-perish.html">Publish or Perish</a></h1>
<p>
As part of my PhD, I am supposed to publish three papers. So far, I have been unable to do so. But this is not about me, I will survive regardless. This is about the <i>systems</i> behind our papers' rejections. Because they are&#x2026; <i>bad</i>. <i>Political</i>. <i>Un-scientific</i>.
</p>

<p>
Our first manuscript was submitted for publications, and got a middling review. If we wanted our work to be published, we were to expand on our introduction to mention the reviewers' favorite publications, and broaden our comparison to include their work. This is considered normal. In the second round of reviews we then got rejected, because our introduction was now too long, and our comparison too broad.
</p>

<p>
The reviews additionally claimed that "novelty cannot be claimed for something that is not validated and compared to state of the art" and that "[our work lacks] formal statistical evaluation of the estimation performance". Which is certainly true, but is also true of every other work published on the same topic in the last five years (I checked). We showed this evidence to the reviewers, but it was not even deemed worthy of a comment.
</p>

<p>
In hindsight however, we realized that we had included at least one reviewer's own algorithms in our comparison, and found it lacking. Their work had only ever been tested, publicly, with a single example recording, where it worked well. Our comparison did the same with twenty thousand recordings, which highlighted some issues. So our paper was rejected. Of course we can't be sure that this was ultimately true, as the reviewers' names are not disclosed to the reviewees (but certainly vice-versa).
</p>

<p>
Our next submission was to a different journal. This time, we had learned from our mistakes, and kept the scope of our investigation more minimal. There would be only a very small comparison, and we would be very careful not to step on anyone else's toes. The review was, again, negative.
</p>

<p>
This time, the grounds for rejection were lack of comparison to state of the art (not a winning move, see above), and our too high false negative rate. Additionally, it contained wonderful verbiage like:
</p>

<blockquote>
<p>
The are many methods that are very similar to the presented method in the sense of being feature extraction methods operating in the STFT domain.
</p>
</blockquote>

<p>
&#x2026;which is just patently ridiculous. If being a "feature extraction method in the STFT domain" was grounds for rejection, there would be <i>no</i> publications in our area of research. And let's ignore for a minute that our publication was not, in fact, such a method.
</p>

<p>
Again, hindsight showed the real culprit: Our manuscript reported a high false negative rate of roughly 50%. Had we just <i>not mentioned this</i>, no one would have noticed. That is what everyone else is doing. More importantly however, reporting on false positive/negative rates in our evaluation called into question every other publication that hadn't. And we can't have that.
</p>

<p>
Another submission was liked because no one had done anything similar before, and was found to provide value to many researchers, but rejected because it still somehow "lacked novelty".
</p>

<p>
So, in summary, our first submission was rejected because it made one of the reviewers look bad, and the second because we not only wanted to report on our method's advantages, but also its shortcomings. Worse, in following the evidence where it lead, we had created new error measures that could potentially find flaws in existing publications, which could potentially make a whole lot of researchers look bad.
</p>

<p>
After five years of dealing with this, I am thoroughly disheartened. Instead of a system for disseminating knowledge, I have found the scientific publishing system a political outlet for the famous, and a lever for keeping uncomfortable knowledge suppressed. This is not the scientific world I want to live in, and apparently, it doesn't want me to live in it, either.
</p>
<div class="taglist"><a href="tags.html">Tags:</a> <a href="tag-science.html">science</a> </div>
<div class="post-date">11 May 2019</div><h1 class="post-title"><a href="2019-05-11-fuji-zoom-lenses.html">Fuji Zoom Lenses</a></h1>
<p>
So I bought a new camera. Now I need new lenses. In this post, I am looking for a standard zoom lens, i.e. something that covers a bit of wide-angle, all the way through the normal range, up to a bit of telephoto. In Fuji's lineup <a href="https://camerasize.com/compact/#721.706,721.421,721.359,721.426,721.448,721.388,ha,t">these needs are met by</a>
</p>

<ul class="org-ul">
<li><del>the XC 15‑45 mm f/3.5‑5.6 OIS PZ (€ 150, 136 g, 4.4 cm)</del></li>
<li>the XC 16‑50 mm f/3.5‑5.6 OIS II (€ 150, 195 g, 6.5 cm)</li>
<li>the XF 18‑55 mm f/2.8‑4 R LM OIS (€ 250, 310 g, 7.0 cm)</li>
<li>the XF 18‑135 mm f/3.5‑5.6 R LM OIS WR (€ 500, 490g, 9.8 cm)</li>
<li><del>the XF 16‑55 mm f/2.8 R LM WR (€ 650, 655 g, 10.6 cm)</del></li>
<li><del>a bag of primes (€ inf, many g, lots of cm)</del></li>
<li>the XF 27 mm f/2.8 (€ 150, 78 g, 2.3 cm)</li>
</ul>

<p>
The XC 15‑45 is out, because the zoom ring is not turn-to-zoom like any other zoom lens. I tried it; I couldn't stand it. The XF 16‑55 is out because it is just too expensive and big for me. A bag of primes is not what I want, but I included the XF 27, because that's what I happened to have at hand. All of the above prices are used prices as of early 2019 in Germany.
</p>


<figure>
<img src="https://bastibe.de/static/2019-05/lenses.jpg" alt="lenses.jpg">

<figcaption><span class="figure-number">Figure 1: </span>From left to right, the XC 16‑50, XF 27, XF 18‑135, XF 18‑55</figcaption>
</figure>

<p>
Before we get started, all of these lenses are perfectly sharp to my eyes. At least in the center-ish area of the image, every pixel shows different information, which is not something I could have said about some of the Nikon lenses I used to own. Because of that, I will not compare sharpness.
</p>

<p>
The word of mouth is that the XF 18‑55 is a stellar kit lens, the XC 16‑50 is a bit cheap, and the XF 18‑135 a bit of a compromise. If internet forums are to be believed, these differences are massive, and the XF 18‑55 is really the only acceptable non-prime lens any self-respecting Fuji fanboy can buy. But then again, that's what internet forums <i>would</i> say, right?
</p>

<p>
With that out of the way, let's have a look at these lenses! I'll use crops from a terribly boring shot <a href="https://bastibe.de/static/2019-05/example.jpg">linked here</a> for most of my examples. Why this shot? Because a), that's what was available, and b), because it contains areas that nicely showcase these lenses' qualities. All shots were taken at f/8 at 27 mm, ISO 400 and a shutter speed around 1/300 s.
</p>

<div id="outline-container-org844762f" class="outline-2">
<h2 id="org844762f">Micro Contrast</h2>
<div class="outline-text-2" id="text-org844762f">
<p>
I often read that micro contrast really tells lenses apart. To illustrate this point, here's an area with very little overall contrast, particularly between the fence and the orange paint, and the fence and the gray stairs:
</p>


<figure>
<a href="https://bastibe.de/static/2019-05/microcontrast.jpg"><img src="https://bastibe.de/static/2019-05/microcontrast.jpg" alt="microcontrast.jpg"></a>

<figcaption><span class="figure-number">Figure 2: </span>100% crops, mouse pointers near the critical areas. (Click to view bigger)</figcaption>
</figure>

<p>
If you look very closely, you might find the fence slightly less visible on the XC 16‑50 than on the XF 18‑135 and XF 27, and ever so slightly more visible on the 18‑55. But it should also be obvious that these differences are <i>incredibly</i> tiny, and not worth fussing over.
</p>
</div>
</div>

<div id="outline-container-org2f637f4" class="outline-2">
<h2 id="org2f637f4">Corner Sharpness and Chromatic Aberrations</h2>
<div class="outline-text-2" id="text-org2f637f4">
<p>
Another common point is corner sharpness, which is typically said to strongly favor primes. This time, the images are cropped from the bottom-right corner of the image that contains some detail, but most importantly a bright white warning sign:
</p>


<figure>
<a href="https://bastibe.de/static/2019-05/cornersharpness.jpg"><img src="https://bastibe.de/static/2019-05/cornersharpness.jpg" alt="cornersharpness.jpg"></a>

<figcaption><span class="figure-number">Figure 3: </span>100% crops of the image corner. (Click to view bigger)</figcaption>
</figure>

<p>
And indeed, the XC 16‑50 is noticeably blurry this time, with the other three lenses similarly sharp. The warning sign also highlights color fringes on the transitions from the bright white sign to the dark background. These chromatic aberrations are almost invisible on the XF 18‑55, and mild on the XF 18‑135 and XF 27.
</p>

<p>
Bear in mind, however, that these are 100% crops in the very furthest corners of a high-contrast image. In normal pictures, none of these issues will be noticeable unless you really zoom in on fine details at the edges of your frame. The chromatic aberrations seen here were already treated in software with the <i>lens correction</i> module in Darktable, but it might be possible to improve on these results with more dedicated processing.
</p>
</div>
</div>

<div id="outline-container-org2176479" class="outline-2">
<h2 id="org2176479">Update 1: Even more comparison pictures</h2>
<div class="outline-text-2" id="text-org2176479">
<p>
After publishing the blog post, I still wasn't satisfied: What if the results I got were only true at f/8? What if image quality got worse at a longer focal length? How does my XF 18 stack up?
</p>

<p>
To answer this, I took another set of pictures and prepared another composite of an crops near the image center, and another one near the lower right corner.
</p>


<figure>
<a href="https://bastibe.de/static/2019-05/centersharpness_big.jpg"><img src="https://bastibe.de/static/2019-05/centersharpness_big.jpg" alt="centersharpness_big.jpg"></a>

<figcaption><span class="figure-number">Figure 4: </span>100% crops of the image center. (Click to view bigger)</figcaption>
</figure>


<figure>
<a href="https://bastibe.de/static/2019-05/cornersharpness_big.jpg"><img src="https://bastibe.de/static/2019-05/cornersharpness_big.jpg" alt="cornersharpness_big.jpg"></a>

<figcaption><span class="figure-number">Figure 5: </span>100% crops of the image corner. (Click to view bigger)</figcaption>
</figure>

<p>
To be perfectly honest, I can not see any significant differences between any of these pictures. At this point, I am starting to question the entire concept of sharpness and micro contrast for evaluating lenses. But at least I learned a lot about how to use the Gimp.
</p>

<p>
As a sanity check, I repeated the experiment with my old Nikon 18-200, and this was in fact noticeably less sharp. And slightly overexposed. And slightly off-color. That's why I switched to Fuji. But as I said, this was a sanity check, not a fair comparison, as the Nikon D7000 body is much older than my Fuji X-E3, and the lens has surely seen better days as well.
</p>
</div>
</div>

<div id="outline-container-orgc583230" class="outline-2">
<h2 id="orgc583230">Update 1: Ergonomics and Balance</h2>
<div class="outline-text-2" id="text-orgc583230">
<p>
The XC 16‑50 and XF 27 operate their aperture with the control wheel on your right thumb. The XC 18, XF 18‑55, and XF 18‑135 have a dedicated aperture ring on the lens instead. Thus, the former two lenses can be controlled with the right hand alone, while the latter two require the left hand on the lens barrel. Zoom is always controlled on the barrel, though.
</p>

<p>
This preference for one-handed or two-handed operation is supported by the lenses' weight, as well: My camera, the X-E3, weighs about 330 g. With the 200 g XC 16‑50, the weight is mostly in the camera body, and can easily be held and operated with one hand. The 250 g XF 18‑55 and the 500 g XF 18‑135 are more lens-heavy, which makes a two-handed grip necessary, which is a better fit for the aperture ring on the lens.
</p>

<p>
Personally, I actually prefer the aperture on the thumb wheel over the unmarked aperture rings on the XF 18‑55 and the XF 18‑135. It just feels more natural in my hands. On the other hand, I like the marked aperture ring on the XF 18, particularly for resetting the aperture without looking through the viewfinder, or when the camera is turned off. In fact, I find the ability to operate the camera while turned off to be very useful in general. It is one of the major reasons why I like Fuji cameras.
</p>
</div>
</div>

<div id="outline-container-org60f3bd6" class="outline-2">
<h2 id="org60f3bd6">Update 2: Image Stabilization</h2>
<div class="outline-text-2" id="text-org60f3bd6">
<p>
In order to assess the image stabilization systems built into these lenses, I took a series pictures of a static subject at 18 mm, 27 mm, and 50 mm, for shutter speeds of 1/30 s, 1/15 s, 1/8 s, 1/4 s, and 1/2 s. I then looked at five images for every combination of lens, focal length, and shutter speed, and labeled them either <i>sharp</i> if there was no visible blur at all, or <i>usable</i> if there was micro-shake only visible at 100 %, or <i>miss</i> if the shot was too blurry.
</p>

<p>
The XC 16‑50 had perfect sharpness at 1/30 s, was at least ok between 1/15 s and 1/8 s, and even 1/4 s still had a few usable shots. 1/2 s or longer was unusable. There was no significant difference between the focal lengths. That last bit is really interesting, as I would have expected shorter focal lengths to be easier to hand-hold than longer ones.
</p>

<p>
The XF 18‑55 stayed perfectly sharp one stop longer until 1/15 s, but otherwise performed exactly the same as the XC 16‑50. I would guess that the small difference in stability between these two lenses is mostly due to their weight difference, but that the image stabilization system is identical.
</p>

<p>
The XF 18‑135, however, was another matter: All shots up until 1/8 s were perfectly sharp, and remained at least usable until 1/2 s! Only at 1 s of shutter speed did I see significant numbers of missed shots! Again, there was no significant difference across focal lengths.
</p>

<p>
With disabled image stabilization, I could hand-hold most shots for at most 1/focal length, but missed or fudged a few shots even there.
</p>

<p>
In summary, I found the XC 16‑50 and XF 18‑55 image stabilization good for about two stops, and astonishingly, the XF 18‑135 stable for a full four stops over my personal hand-holding skills. Some of that stability is no doubt due to the increased weight of the XF 18‑135, but nevertheless, I find these results astonishing!
</p>
</div>
</div>

<div id="outline-container-org0dbee2b" class="outline-2">
<h2 id="org0dbee2b">Close Focus Distance and Magnification</h2>
<div class="outline-text-2" id="text-org0dbee2b">
<p>
And now, the darling of all photographers: out-of-focus backgrounds. Common wisdom is that the bigger the aperture, the more the background is thrown out of focus. But that's only part of the truth, and honestly, not the most interesting part for these kinds of limited-aperture lenses. Much more powerful is getting closer to your subject: The closer you focus, and the farther away your background, the more the background will be <i>out</i> of focus. This effect gets even stronger when you zoom in.
</p>


<figure>
<a href="https://bastibe.de/static/2019-05/magnification.jpg"><img src="https://bastibe.de/static/2019-05/magnification.jpg" alt="magnification.jpg"></a>

<figcaption><span class="figure-number">Figure 6: </span>Widest (top) and longest (bottom) shots, each cropped vertically but not horizontally. All shots at f/5.6. (Click to view bigger)</figcaption>
</figure>

<p>
The XC 16‑50 focuses much more closely than any other lens in this list, at 12 and 30 cm (Fuji says 15 cm). You can get really nice background separation with this lens, and great magnification in your macro shots. The XF 18‑55 focuses at 25 and 35 cm (Fuji: 40 cm), which is not particularly impressive. The XF 18‑135 focuses even farther, at 33 and 43 cm (Fuji: 45 cm), but gains magnification through its long tele zoom. The XF 27 is not optimized for this kind of thing at all, at 29 cm (Fuji: 34 cm).
</p>
</div>
</div>

<div id="outline-container-orga14266b" class="outline-2">
<h2 id="orga14266b">Conclusions</h2>
<div class="outline-text-2" id="text-orga14266b">
<p>
To me, the XC 16‑50 is the winner for a small/light zoom kit. It might be the least great option optically, but the differences are not dramatic at all, and it is the cheapest, smallest, and lightest lens with the most useful wide end and the closest focusing. But it lacks a dedicated aperture ring and is a plastic construction instead of a metal one, which does detract from the haptic joy somewhat.
</p>

<p>
The XF 18‑55 is optically the strongest lens. It might even beat the XF 27 prime lens on its own turf! But the optical differences to the cheaper XC 16‑50 and the more versatile XF 18‑135 are quite small, and are not be worth the price/weight/inconvenience to me.
</p>

<p>
The XF 18‑135 is really surprisingly good. The much longer focal range necessarily comes with compromises in optical quality and bulk, but it seems no significant corners where cut in this case. And the image stabilization is a significant step above the other two lenses. Considering that this lens usually replaces at least two other lenses, I even find the price reasonable. This is my first choice as a do-everything zoom kit.
</p>

<p>
The XF 27 is not very strong in any particular way, <i>except size</i>. And that size trumps all. If I just want to throw a camera in my bag without any particular photographic intentions, the XF 27 is my first choice. And possibly the XF 18, if I still have room in my bag.
</p>

<p>
As some small buying advice, the XC 16‑50 was refreshed in 2015 with the <i>OIS II</i> version, which introduced that nice close focusing distance (highly recommended). The XF 18‑135 was apparently built in two batches, the original <i>made in China</i> version that seemed to have horrible QA issues, and a second <i>made in Philippines</i> version in 2017 without.
</p>
</div>
</div>

<div id="outline-container-orgf6b4c4f" class="outline-2">
<h2 id="orgf6b4c4f">What I didn't mention</h2>
<div class="outline-text-2" id="text-orgf6b4c4f">
<p>
Aperture. The XF 18‑55 and XF 27 have a wider maximum aperture than the XC 16‑50 or XF 18‑135, by about two thirds of a stop. Shooting at bigger apertures makes brighter pictures with stronger background blur, and some loss in sharpness. I don't find the optical performance wide-open particularly interesting, because most of the time I'd use large apertures to blur the background, making sharpness and distortion mostly irrelevant. And as I said above, getting closer is usually more effective for background blur than maximum aperture, anyway.
</p>

<p>
Image stabilization. The three zooms offer optical image stabilization systems. From what I can tell, the XF 18‑135 is significantly more effective in this regard than the XC 16‑50 or the XF 18‑55. Hand-held shots with up to about 1/10th of a second seem easily achievable with the XF 18‑135, whereas the unstabilized XF 27 becomes blurry at 1/40th. Videos are noticeably smoother with the XF 18‑135 as well.
</p>

<p>
Weather sealing. The XF 18‑135 is weather sealed, the other lenses are not. My camera is not, so I don't care.
</p>

<p>
Distortion and Vignetting. Is fixed in post. No need obsessing over it.
</p>

<p>
Autofocus speed. Is good. No need obsessing over it.
</p>
</div>
</div>
<div class="taglist"><a href="tags.html">Tags:</a> <a href="tag-photography.html">photography</a> </div>
<div class="post-date">25 Mar 2019</div><h1 class="post-title"><a href="2019-03-25-on-camera-sensor-sizes.html">On camera sensor sizes</a></h1>
<p>
A common internet wisdom about photography is that bigger camera sensors capture more light. So if you want to work in low light, you need a full frame camera, and a bigger sensor always produces better image quality. I have struggled with this a lot. It just doesn't make sense: Lenses can focus light on any surface, so <i>why should the surface size matter</i>?
</p>

<p>
The answer turns out to be&#x2026; disappointing. Big-sensor cameras allow for larger (practical) apertures, and lower base ISO. But less noise for the same picture is simply impossible with the same sensor technology. Because that's not how physics works. Let me explain.
</p>

<p>
<i>At this point, I had previously launched into a long-winded explanation on <a href="https://photographylife.com/equivalence-also-includes-aperture-and-iso">equivalence</a>, and reached a slightly misguided conclusion. So here's a better one:</i>
</p>

<p>
It is possible to build <i>equivalent</i> lenses for differently sized sensors, which capture the same amount of light, with the same depth of field, and the same field of view, but simply project this light on a differently sized sensor. Or you can use a "speed booster", which adapts a "bigger" lens to a "smaller" sensor. Both of these will give you identical images, and identical amounts of noise (if the same sensor technology is used).
</p>

<p>
As an example, a micro four thirds 23mm f/1.4 lens produces identical images to an APS-C 35mm f/2 lens or a full frame 50mm f/2.8 lens. You might notice that \(\frac{23}{1.4} = \frac{35}{2} = \frac{50}{2.8}\), which means each of these lenses will have the same physical aperture size, and therefore admit the same amount of light. And be the same size and weight. Since the smaller sensor collects the same light on a smaller area, the image will be brighter, and will need to use a lower ISO for the same exposure. And since lower ISO produces less noise, the "one stop advantage" of bigger sensors is bunk, <i>if equivalent lenses are used</i>.
</p>

<p>
The one remaining difference between sensor sizes is that bigger photosites carry more charge, which means more dynamic range at base ISO on a bigger sensor. This is only a factor if you indeed shoot at base ISO.
</p>

<p>
<i>But</i>, that's not the interesting part. Camera manufacturers cleverly designed their product lines such that small-sensor cameras are physically smaller, and get smaller lenses, while large-sensor cameras are bigger, with bigger lenses. Thus, if you want to get access to the most fancy glass, you will have to use a bigger, more expensive camera body as well. And inversely, if you want to use the most compact glass, it will only be available on smaller, less expensive camera bodies. And that's not pure marketing, either, as bigger lenses require bigger bodies to hold them comfortably, while smaller lenses balance better on a smaller body.
</p>

<p>
So in the end, it comes down to a compromize: If you want/need the best glass, it will only be available on the bigger bodies with the bigger sensors. If, on the other hand, you want to go small and light, you will need to sacrifice big apertures, but get access to smaller bodies with smaller sensors. But it's really all about the glass, not the sensor sizes.
</p>
<div class="taglist"><a href="tags.html">Tags:</a> <a href="tag-photography.html">photography</a> </div>
<div class="post-date">13 Mar 2019</div><h1 class="post-title"><a href="2019-03-13-learning-about-photography-sunstars.html">Learning about Photography: Sunstars</a></h1>
<p>
Normally, when you take a picture of something too bright, you get <i>bloom</i>: An all-consuming brightness that plunges everything around it into pure whiteness. Ugly.
</p>

<p>
But if the light source is <i>reeeally</i> tiny, and your aperture is <i>teeeensy</i> as well, you get something else: sunstars
</p>


<figure>
<img src="https://bastibe.de/static/2019-03/sunstar.jpg" alt="sunstar.jpg">

</figure>

<p>
This particular sunstar has fourteen corners, and therefore comes from a seven-bladed aperture (in my Fuji XC 16-50). It happens because tiny apertures are not perfectly circular any longer, but instead, in my case, septagonal, and therefore bloom more in some directions than in others. The effect is kind of beautiful.
</p>

<p>
In this picture, the sun was just barely peeking into the edge between the tree and the building, and my aperture was set to its smallest setting, f22. I actually wanted to capture the raindrops on the branches, which I largely failed at. In the end, the picture didn't turn out very pretty, but at least I got some fine sunstars!
</p>
<div class="taglist"><a href="tags.html">Tags:</a> <a href="tag-photography.html">photography</a> </div><div id="archive">
<a href="archive.html">Other posts</a>
</div>
</div>
</body>
</html>
