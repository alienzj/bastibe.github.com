<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="alternate"
      type="appliation/rss+xml"
      href="http://bastibe.de/rss.xml"
      title="RSS feed for http://bastibe.de/">
<title>Bastibe.de</title><meta  name="author" content="Bastian Bechtold" />
<link href='http://fonts.googleapis.com/css?family=Roboto&subset=latin' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet' type='text/css'>
<link href= "static/style.css" rel="stylesheet" type="text/css" />
<link rel="icon" href="static/favicon.ico">
<link rel="apple-touch-icon-precomposed" href="static/favicon-152.png">
<link rel="msapplication-TitleImage" href="static/favicon-144.png">
<link rel="msapplication-TitleColor" href="#0141ff">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"> </script>
<meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8" />
<meta name="viewport" content="initial-scale=1,width=device-width,minimum-scale=1"></head>
<body>
<div id="preamble" class="status"><div class="header">
  <a href="http://bastibe.de">Basti's Scratchpad on the Internet</a>
  <div class="sitelinks">
    <a href="http://alpha.app.net/bastibe">alpha.app.net</a> | <a href="http://github.com/bastibe">Github</a>
  </div>
</div></div>
<div id="content"><div class="post-date">29 Okt 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-10-29-matlab-engine-leaks.html">Massive Memory Leak in the Matlab Engine for Python</a></h1>
<p>
As of Matlab 2014b, Matlab includes a <a href="http://mathworks.com/help/matlab/matlab-engine-for-python.html">Python module</a> for calling Matlab code from Python. This is how you use it:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">import</span> numpy
<span style="color: #1c86ee;">import</span> matlab
<span style="color: #1c86ee;">import</span> matlab.engine

<span style="color: #2e8b57;">eng</span> = matlab.engine.start_matlab()
<span style="color: #2e8b57;">random_data</span> = numpy.random.randn(100)
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">convert Numpy data to Matlab:</span>
<span style="color: #2e8b57;">matlab_data</span> = matlab.double(random_data.tolist())
<span style="color: #2e8b57;">data_sum</span> = eng.<span style="color: #cd6600;">sum</span>(matlab_data)
</pre>
</div>

<p>
You can call any Matlab function on <code>eng</code>, and you can access any Matlab workspace variable in <code>eng.workspace</code>. As you can see, the Matlab Engine is not Numpy-aware, and you have to convert all your Numpy data to Matlab <code>double</code> before you can call Matlab functions with it. Still, it works pretty well.
</p>

<p>
Recently, I ran a rather large experiment set, where I had a set of four functions, two in Matlab, two in Python, and called each of these functions a few thousand times with a bunch of different data to see how they performed.
</p>

<p>
While doing that I noticed that my Python processes were growing larger and larger, until they consumed all my memory and a sizeable chunk of my swap as well. I couldn't find any reason for this. None of my Python code cached anything, and the sum total of all global variables did not amount to anything substantial.
</p>

<p>
Enter <a href="http://pythonhosted.org/Pympler/index.html">Pympler</a>, a memory analyzer for Python. Pympler is an amazing library for introspecting your program's memory. Among its many features, it can list the biggest objects in your running program:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">from</span> pympler <span style="color: #1c86ee;">import</span> muppy, summary
summary.print_(summary.summarize(muppy.get_objects()))
</pre>
</div>

<pre class="example">
                                      types |   # objects |   total size
=========================================== | =========== | ============
                        &lt;class 'array.array |        1076 |      2.77 GB
                                &lt;class 'str |       42839 |      7.65 MB
                               &lt;class 'dict |        8604 |      5.43 MB
                      &lt;class 'numpy.ndarray |          48 |      3.16 MB
                               &lt;class 'code |       14113 |      1.94 MB
                               &lt;class 'type |        1557 |      1.62 MB
                               &lt;class 'list |        3158 |      1.38 MB
                                &lt;class 'set |        1265 |    529.72 KB
                              &lt;class 'tuple |        5129 |    336.98 KB
                              &lt;class 'bytes |        2413 |    219.48 KB
                            &lt;class 'weakref |        2654 |    207.34 KB
            &lt;class 'collections.OrderedDict |          65 |    149.85 KB
                 &lt;class 'wrapper_descriptor |        1676 |    130.94 KB
  &lt;class 'traitlets.traitlets.MetaHasTraits |         107 |    123.55 KB
                  &lt;class 'getset_descriptor |        1738 |    122.20 KB
</pre>

<p>
Now that is interesting. Apparently, I was lugging around close to three gigabytes worth of bare-Python <code>array.array</code>. And these are clearly not Numpy arrays, since those would show up as <code>numpy.ndarray</code>. But I couldn't find any of these objects in my workspace.
</p>

<p>
So let's get a reference to one of these objects, and see who they belong to. This can also be done with Pympler, but I prefer the way <a href="http://mg.pov.lt/objgraph/">objgraph</a> does it:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">import</span> array
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">get a list of all objects known to Python:</span>
<span style="color: #2e8b57;">all_objects</span> = muppy.get_objects()
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">sort out only `array.array` instances:</span>
<span style="color: #2e8b57;">all_arrays</span> = [obj <span style="color: #1c86ee;">for</span> obj <span style="color: #1c86ee;">in</span> all_objects <span style="color: #1c86ee;">if</span> <span style="color: #cd6600;">isinstance</span>(obj, array.array)]

<span style="color: #1c86ee;">import</span> objgraph
objgraph.show_backrefs(all_arrays[0], filename=<span style="color: #8b7355;">'array.png'</span>)
</pre>
</div>


<div class="figure">
<p><img src="http://bastibe.de/static/2015-10/array.png" alt="array.png" />
</p>
</div>

<p>
It seems that the <code>array.array</code> object is part of a <code>matlab.double</code> instance which is not referenced from anywhere but <code>all_objects</code>. A memory leak.
</p>

<p>
After a bit of experimentation, I found the culprit. To illustrate, here's an example: The function <code>leak</code> passes some data to Matlab, and calculates a float. Since the variables are not used outside of <code>leak</code>, and the function does not return anything, all variables within the function should get deallocated when <code>leak</code> returns.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">leak</span>():
    <span style="color: #2e8b57;">test_data</span> = numpy.zeros(1024*1024)
    <span style="color: #2e8b57;">matlab_data</span> = matlab.double(test_data.tolist())
    eng.<span style="color: #cd6600;">sum</span>(matlab_data)
</pre>
</div>

<p>
Pympler has another great feature that can track allocations. The <code>SummaryTracker</code> will track and display any allocations between calls to <code>print_diff()</code>. This is very useful to see how much memory was used during the call to <code>leak</code>:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">from</span> pympler <span style="color: #1c86ee;">import</span> tracker
<span style="color: #2e8b57;">tr</span> = tracker.SummaryTracker()
tr.print_diff()
leak()
tr.print_diff()
</pre>
</div>

<pre class="example">
                     types |   # objects |   total size
========================== | =========== | ============
       &lt;class 'array.array |           1 |      8.00 MB
...
</pre>

<p>
And there you have it. Note that this leak is not the Numpy array <code>test_data</code> and it is not the matlab array <code>matlab_data</code>. Both of these are garbage collected correctly. But <b>the Matlab Engine for Python will leak any data you pass to a Matlab function</b>.
</p>

<p>
This data is not referenced from anywhere within Python, and is counted as <i>leaked</i> by <code>objgraph</code>. In other words, the C code inside the Matlab Engine for Python copies all passed data into it's internal memory, but never frees that memory. Not even if you quit the Matlab Engine, or <code>del</code> all Python references to it. Your only option is to restart Python.
</p>

<p>
<b>Postscriptum</b>
</p>

<p>
I since posted a bug report on Mathworks, and received a patch that fixes the problem. Additionally, Mathworks said that the problem only occurs on Linux.
</p>
<div class="post-date">16 Okt 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-10-16-finder-woes.html">OS X Finder Woes</a></h1>

<div class="figure">
<p><img src="http://bastibe.de/static/2015-10/Mac.png" alt="Mac.png" />
</p>
</div>

<p>
The Mac. It used to be the most streamlined, thought-through general computing device on the market.
</p>

<p>
Even it's file management used to be top-notch. There were many cool little touches. One particularly useful feature was the <i>Proxy Icon</i>&#x2013;if a window displayed a file's content, that file's icon would show up in the window's title. And you could drag that icon directly onto a thumb drive or email, without having to use the Finder. But the Finder, too, had many neat little features. I loved the fact that when you renamed a file in an alphabetically sorted file list, Finder would not immediately re-shuffle it to its new location, but would wait half a second before doing so. When renaming multiple files, this was really useful, since you could go through them one by one and rename them, simply by pressing arrow keys and return.
</p>

<p>
But as you might have guessed from my use of the past tense, these golden days are gone. The Finder used to know a JPEG from a ZIP regardless of file extension. Now it doesn't any more. The Proxy Icon is still draggable, but it will create an alias instead of a copy&#x2013;perfectly useless on a thumb drive or in an email.
</p>

<p>
And with the newest version of OS X, El Capitan, they finally blew it for me. Before, even though the Finder inexplicably never had the ability to cut and paste files, you could always install programs like <a href="http://totalfinder.binaryage.com/">TotalFinder</a> to fix that. Not so with El Capitan. The Finder now is holy land, and can not be touched any more by third parties. So no more cut and paste, no more un-hiding system files. No more side-by-side Finder tabs. And brand new with El Capitan as well: No more waiting after renaming. Now, when you rename a file, it is immediately re-sorted to its new position, thus making renaming multiple files terribly inconvenient.
</p>

<p>
So, good bye OS X. I updated my work laptop first, and I regret it. I never regretted an OS X update before. My home machine is not going to get the update. It is honestly sad to see my once-beloved Mac platform becoming worse and worse and worse with every new release.
</p>
<div class="post-date">03 Okt 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-10-03-changing-file-creation-dates.html">Changing File Creation Dates in OSX</a></h1>
<p>
On my last vacation, I have taken a bunch of pictures, and a bunch of video. The problem is, I hadn't used the video camera in a long time, and it believed that all it's videos were taken on the first of January 2012. So in order for the pictures to show up correctly in my picture library, I wanted to correct that.
</p>

<p>
For images, this is relatively easy: Most picture libraries support some kind of bulk date changes, and there are a bunch of <a href="http://www.sentex.net/~mwandel/jhead/">command</a> <a href="http://owl.phy.queensu.ca/~phil/exiftool/">line</a> <a href="http://www.exiv2.org/#util">utilities</a> that can do it, too. But none of these tools work for video (exiftool claims be able to do that, but I couldn't get it to work).
</p>

<p>
So instead, I went about to change the file creation date of the actual video files. And it turns out, this is surprisingly hard! The thing is, most Unix systems (a Mac is technically a Unix system) don't even know the concept of a file creation date. Thus, most Unix utilities, including most programming languages, don't know how to deal with that, either.
</p>

<p>
If you have XCode installed, this will come with <code>SetFile</code>, a command line utility that can change file creation dates. Note that <code>SetFile</code> can change <i>either</i> the file creation date, <i>or</i> the file modification date, but not both at the same time, as any normal Unix utility would. Also note that <code>SetFile</code> expects dates in American notation, which is about as nonsensical as date formats come.
</p>

<p>
Anyway, here's a small Python script that changes the file creation date (but not the time) of a bunch of video files:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">import</span> os.path
<span style="color: #1c86ee;">import</span> os
<span style="color: #1c86ee;">import</span> datetime
<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">I want to change the dates on the files GOPR0246.MP4-GOPR0264.MP4</span>
<span style="color: #1c86ee;">for</span> index <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(426, 465):
    <span style="color: #2e8b57;">filename</span> = <span style="color: #8b7355;">'GOPR0{}.MP4'</span>.<span style="color: #cd6600;">format</span>(index)
    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">extract old date:</span>
    <span style="color: #2e8b57;">date</span> = datetime.datetime.fromtimestamp(os.path.getctime(filename))
    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">create a new date with the same time, but on 2015-08-22</span>
    <span style="color: #2e8b57;">new_date</span> = datetime.datetime(2015,  8, 22, date.hour, date.minute, date.second)
    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">set the file creation date with the "-d" switch, which presumably stands for "dodification"</span>
    os.system(<span style="color: #8b7355;">'SetFile -d "{}" {}'</span>.<span style="color: #cd6600;">format</span>(new_date.strftime(<span style="color: #8b7355;">'%m/%d/%Y %H:%M:%S'</span>), filename))
    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">set the file modification date with the "-m" switch</span>
    os.system(<span style="color: #8b7355;">'SetFile -m "{}" {}'</span>.<span style="color: #cd6600;">format</span>(new_date.strftime(<span style="color: #8b7355;">'%m/%d/%Y %H:%M:%S'</span>), filename))
</pre>
</div>
<div class="post-date">29 Sep 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-09-29-numpy-broadcasting-rules.html">Numpy Broadcasting Rules</a></h1>
<p>
They say that all arithmetic operations in Numpy behave like their element-wise cousins in Matlab. This is wrong, and seriously tripped me up last week.
</p>

<p>
In particular, this is what happens when you multiply an array with a matrix<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup> in Numpy:
</p>

<pre class="example">
     [[  1],           [[1, 2, 3],       [[ 1,    2,   3],
      [ 10],       *    [4, 5, 6],   =    [ 40,  50,  60],
      [100]]            [7, 8, 9]]        [700, 800, 900]]

 [  1,  10, 100]       [[1, 2, 3],       [[  1,  20, 300],
        OR         *    [4, 5, 6],   =    [  4,  50, 600],
[[  1,  10, 100]]       [7, 8, 9]]        [  7,  80, 900]]
</pre>

<p>
They behave as if each row was evaluated separately, and singular dimensions are repeated where necessary. It helps to think about them as row-wise, instead of element-wise. This is particularly important in the second example, where the <i>whole</i> 1d-array is multiplied with <i>every row</i> of the 2d-array.
</p>

<p>
Note that this is <i>not</i> equivalent to multiplying every <i>element</i> as in <code>[a[n]*b[n] for n in range(len(a))]</code>. I guess that's why this is called <i>broadcasting</i>, and not <i>element-wise</i>.
</p>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
"matrix" here refers to a 2-d <code>numpy.array</code>. There is also a <code>numpy.matrix</code>, where multiplication is matrix multiplication, but this is not what I'm talking about.
</p></div></div>


</div>
</div><div class="post-date">28 Sep 2015</div><h1 class="post-title"><a href="http://bastibe.de/2015-09-28-python-performance.html">Python Numeric Performance</a></h1>
<p>
Recently, I was working on a dynamic programming algorithm that involves a lot of number crunching in nested loops. The algorithm looks like this:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_change_probability_python</span>(oct_per_sec):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">b</span> = 1.781
    <span style="color: #2e8b57;">mu</span> = -0.301
    <span style="color: #1c86ee;">return</span> 1/(2*b)*math.exp(-<span style="color: #cd6600;">abs</span>(oct_per_sec-mu)/b)

<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_idx_range_python</span>(y_idx, max_y_factor, height):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">y</span> = (y_idx/height)*(max_y-min_y)+min_y
    <span style="color: #2e8b57;">y_lo</span> = <span style="color: #cd6600;">max</span>(y/max_y_factor, min_y)
    <span style="color: #2e8b57;">y_hi</span> = <span style="color: #cd6600;">min</span>(y*max_y_factor, max_y)
    <span style="color: #2e8b57;">y_lo_idx</span> = <span style="color: #cd6600;">int</span>((y_lo-min_y)/(max_y-min_y)*height)
    <span style="color: #2e8b57;">y_hi_idx</span> = <span style="color: #cd6600;">int</span>((y_hi-min_y)/(max_y-min_y)*height)
    <span style="color: #1c86ee;">return</span> y_lo_idx, y_hi_idx

<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">find_tracks_python</span>(cost_matrix, delta_x):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">tracks</span> = np.zeros(correlogram.shape, dtype=np.int64)
    <span style="color: #2e8b57;">cum_cost</span> = np.zeros(correlogram.shape)

    <span style="color: #2e8b57;">max_y_factor</span> = (2**5)**(delta_x)
    <span style="color: #2e8b57;">height</span> = correlogram.shape[1]

    <span style="color: #2e8b57;">probabilities</span> = np.empty((height, height))
    <span style="color: #1c86ee;">for</span> y_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(height):
        <span style="color: #2e8b57;">y</span> = (y_idx/height)*(max_y-min_y)+min_y
        <span style="color: #1c86ee;">for</span> y_pre_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(*y_idx_range_numba(y_idx, max_y_factor, height)):
            <span style="color: #2e8b57;">y_pre</span> = (y_pre_idx/height)*(max_y-min_y)+min_y
            <span style="color: #2e8b57;">doubles_per_x</span> = math.log2((y/y_pre)**(1/delta_x))
            <span style="color: #2e8b57;">probabilities</span>[y_idx, y_pre_idx] = y_change_probability_numba(doubles_per_x)

    <span style="color: #1c86ee;">for</span> x_idx, cost_column <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">enumerate</span>(cost_matrix):
        <span style="color: #1c86ee;">if</span> x_idx == 0:
            <span style="color: #2e8b57;">cum_cost</span>[x_idx] = cost_column
            <span style="color: #1c86ee;">continue</span>
        <span style="color: #1c86ee;">for</span> y_idx, cost <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">enumerate</span>(cost_column):
            <span style="color: #1c86ee;">for</span> y_pre_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(*y_idx_range_numba(y_idx, max_y_factor, height)):
                <span style="color: #2e8b57;">weighted_cum_cost</span> = cum_cost[x_idx-1, y_pre_idx] + cost*probabilities[y_idx, y_pre_idx]
                <span style="color: #1c86ee;">if</span> weighted_cum_cost &gt; cum_cost[x_idx, y_idx]:
                    <span style="color: #2e8b57;">cum_cost</span>[x_idx, y_idx] = weighted_cum_cost
                    <span style="color: #2e8b57;">tracks</span>[x_idx, y_idx] = y_pre_idx
            <span style="color: #2e8b57;">cum_cost</span>[x_idx, y_idx] = cum_cost[x_idx-1, tracks[x_idx, y_idx]] + cost

    <span style="color: #1c86ee;">return</span> tracks, cum_cost
</pre>
</div>

<p>
I'm not going into the details of what this algorithm does, but note that it iterates over every column and row of the matrix <code>cost_matrix</code>, and then iterates over another range <code>previous_y_range</code> for each of the values in <code>cost_matrix</code>. On the way, it does a lot of basic arithmetic and some algebra.
</p>

<p>
The problem is, this is very slow. For a \(90 \times 200\) <code>cost_matrix</code>, this takes about 260 ms. Lots of loops? Lots of simple mathematics? Slow? That sounds like a perfect match for <a href="http://www.numpy.org/">Numpy</a>!
</p>

<p>
If you can express your code in terms of linear algebra, Numpy will execute them in highly-optimized C code. The problem is, translating loops into linear algebra is not always easy. In this case, it took some effort:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_change_probability_numpy</span>(doubles_per_x):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">b</span> = 1.781
    <span style="color: #2e8b57;">mu</span> = -0.301
    <span style="color: #1c86ee;">return</span> 1/(2*b)*np.exp(-np.<span style="color: #cd6600;">abs</span>(doubles_per_x-mu)/b)

<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">find_frequency_tracks_numpy</span>(cost_matrix, delta_x):
    <span style="color: #8b7355;">""" ... """</span>
    <span style="color: #2e8b57;">tracks</span> = np.zeros(cost_matrix.shape, dtype=np.<span style="color: #cd6600;">int</span>)
    <span style="color: #2e8b57;">cum_cost</span> = np.zeros(cost_matrix.shape)

    <span style="color: #2e8b57;">max_y_factor</span> = (2**5)**(delta_t) <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">allow at most 5 octaves per second (3 sigma)</span>
    <span style="color: #2e8b57;">height</span> = cost_matrix.shape[1]

    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">pre-allocate probabilities matrix as minus infinity. This matrix</span>
    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">will be sparsely filled with positive probability values, and</span>
    <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">empty values will have minus infinite probability.</span>
    <span style="color: #2e8b57;">probabilities</span> = -np.ones((height, height))*np.inf
    <span style="color: #1c86ee;">for</span> y_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(probabilities.shape[0]):
        <span style="color: #2e8b57;">y</span> = (y_idx/height)*(max_y-min_y)+min_y
        <span style="color: #2e8b57;">y_pre_idx</span> = np.arange(<span style="color: #cd6600;">int</span>((<span style="color: #cd6600;">max</span>(y/max_y_factor, min_y)-min_y)/(max_y-min_y)*height),
                              <span style="color: #cd6600;">int</span>((<span style="color: #cd6600;">min</span>(y*max_y_factor, max_y)-min_y)/(max_y-min_y)*height))
        <span style="color: #2e8b57;">y_pre</span> = (y_pre_idx/height)*(max_y-min_y)+min_y
        <span style="color: #2e8b57;">doubles_per_x</span> = np.log2((y/y_pre)**(1/delta_x))
        <span style="color: #2e8b57;">probabilities</span>[y_idx, y_pre_idx] = y_change_probability(doubles_per_x)

    <span style="color: #2e8b57;">cum_cost</span>[0] = cost_matrix[0]
    <span style="color: #1c86ee;">for</span> x_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(1, <span style="color: #cd6600;">len</span>(cost_matrix)):
        <span style="color: #2e8b57;">cost_column</span> = cost_matrix[x_idx:x_idx+1] <span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">extract cost_column as 2d-vector!</span>
        <span style="color: #2e8b57;">weighted_cum_cost</span> = cum_cost[x_idx-1] + cost_column.T*probabilities
        <span style="color: #2e8b57;">tracks</span>[x_idx] = np.argmax(weighted_cum_cost, axis=1)
        <span style="color: #2e8b57;">cum_cost</span>[x_idx] = cum_cost[x_idx-1, tracks[x_idx]] + cost_column

    <span style="color: #1c86ee;">return</span> tracks, cum_corrs
</pre>
</div>

<p>
This code does not look much like the original, but calculates exactly the same thing. This takes about 15 ms for a \(90 \times 200\) <code>cost_matrix</code>, which is about 17 times faster than the original code! Yay Numpy! And furthermore, this code is arguably more readable than the original, since it is written at a higher level of abstraction.
</p>

<p>
Another avenue for performance optimization is <a href="http://numba.pydata.org/">Numba</a>. Numba applies dark and powerful magic to compile humble Python functions into blazingly fast machine code. It is proper magic, if you ask me. Simply add an innocuous little decorator to your functions, and let Numba do it's thing. If all goes well, your code will work just as before, except with unheard-of performance:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #00688b;">@jit</span>(numba.float64(numba.float64), nopython=<span style="color: #6e8b3d;">True</span>)
<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_change_probability_numba</span>(doubles_per_x):
    ...

<span style="color: #00688b;">@jit</span>((numba.int64, numba.float64, numba.int64), nopython=<span style="color: #6e8b3d;">True</span>)
<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">y_idx_range_numba</span>(y_idx, max_y_factor, height):
    ...

<span style="color: #00688b;">@jit</span>((numba.float64[:,:], numba.float64), nopython=<span style="color: #6e8b3d;">True</span>)
<span style="color: #1c86ee;">def</span> <span style="color: #cd9b1d;">find_tracks_numba</span>(cost_matrix, delta_t):
    ...
</pre>
</div>

<p>
However, Numba is no silver bullet, and does not support all of Python yet. In the present case, it is missing support for <code>enumerate</code> for Numpy matrices. Thus, I had to rewrite the first two loops like this:
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">python version</span>
<span style="color: #1c86ee;">for</span> x_idx, cost_column <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">enumerate</span>(cost_matrix):
    ...

<span style="color: #7f7f7f;"># </span><span style="color: #7f7f7f;">numba version</span>
<span style="color: #1c86ee;">for</span> x_idx <span style="color: #1c86ee;">in</span> <span style="color: #cd6600;">range</span>(<span style="color: #cd6600;">len</span>(cost_matrix)):
    <span style="color: #2e8b57;">cost_column</span> = cost_matrix[x_idx]
    ...
</pre>
</div>

<p>
Another area that proved problematic is N-D slice writing. Instead of using expressions like <code>m1[x,y:y+3] = m2</code>, you have to write <code>for idx in range(3): m1[x,y+idx] = m2[idx]</code>. Not a difficult transformation, but it basically forced me to unroll all the nice vectorized code of the Numpy version back to their original pure-Python form. That said, Numba is getting better and better, and many constructs that used to be uncompilable (<code>yield</code>) are not a problem any more.
</p>

<p>
Anyway, with that done, the above code went down from 260 ms to 2.2 ms. This is a 120-fold increase in performance, and still seven times faster than Numpy, with minimal code changes. This is proper magic!
</p>

<p>
So why wouldn't you just always use Numba? After all, when it comes down to raw performance, Numba is the clear winner. The big difference between performance optimization using Numpy and Numba is that properly vectorizing your code for Numpy often reveals simplifications and abstractions that make it easier to reason about your code. Numpy forces you to think in terms of vectors, matrices, and linear algebra, and this often makes your code <i>more beautiful</i>. Numba on the other hand often requires you to make your code <i>less beautiful</i> to conform to it's subset of compilable Python.
</p>
<div id="archive">
  <a href="archive.html">Older posts</a>
</div>
</div>
</body>
